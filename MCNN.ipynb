{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKwqUhKrR3jcbzihGDOxYo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0422alsrud/ml/blob/master/MCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qfa02UPS1WfM",
        "outputId": "ba2a52b4-f151-4b0f-dd20-02f98a6ea278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.5.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (2.9.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (1.7.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (2.6.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.15.0)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting image-classifiers==0.2.2\n",
            "  Downloading image_classifiers-0.2.2-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 566 kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from image-classifiers==0.2.2) (2.9.0)\n",
            "Installing collected packages: image-classifiers\n",
            "Successfully installed image-classifiers-0.2.2\n"
          ]
        }
      ],
      "source": [
        "# Verify GPU Integration\n",
        "%tensorflow_version 2.x \n",
        "%pip install -U --pre efficientnet\n",
        "%pip install -U image-classifiers==0.2.2\n",
        "import tensorflow as tf\n",
        "#device_name = tf.test.gpu_device_name()\n",
        "#if device_name != '/device:GPU:0':\n",
        "#  raise SystemError('Alert: GPU Device Not Found!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "# gh repo clone \n",
        "!git clone https://github.com/anindox8/Ensemble-of-Multi-Scale-CNN-for-Dermatoscopy-Classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlAhYXKC1ZCJ",
        "outputId": "f7da9046-a538-42ea-9232-112d526282f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Cloning into 'Ensemble-of-Multi-Scale-CNN-for-Dermatoscopy-Classification'...\n",
            "remote: Enumerating objects: 132, done.\u001b[K\n",
            "remote: Counting objects: 100% (132/132), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 132 (delta 29), reused 75 (delta 11), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (132/132), 10.02 MiB | 17.18 MiB/s, done.\n",
            "Resolving deltas: 100% (29/29), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Project Folder\n",
        "\n",
        "%cd \"/content/Ensemble-of-Multi-Scale-CNN-for-Dermatoscopy-Classification/scripts\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gj22Tsm1hbQ",
        "outputId": "2900eaa5-28e0-4716-e183-1a0b4e9fa316"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Ensemble-of-Multi-Scale-CNN-for-Dermatoscopy-Classification/scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Current Directory\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR1KAVVX2U9Y",
        "outputId": "e5e84aa7-c7ef-4999-ee57-39454e94907c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mclassification_models\u001b[0m/  ensemble-test.ipynb  train-val.ipynb\n",
            "color-io.ipynb          ensemble-val.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "from __future__ import unicode_literals\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "from __future__ import absolute_import\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "from skimage import filters as skifilters\n",
        "from scipy import ndimage\n",
        "from skimage import filters\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import h5py\n",
        "import time\n",
        "import json\n",
        "import warnings\n",
        "import dill\n",
        "from sklearn.metrics import (roc_curve, auc, accuracy_score, f1_score, precision_score, \n",
        "                             recall_score, classification_report, confusion_matrix)\n",
        "from scipy import interp\n",
        "import efficientnet.tfkeras as efn\n",
        "from classification_models.tfkeras import Classifiers as aux_models"
      ],
      "metadata": {
        "id": "_TidyCAx2XGX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network Parameters\n",
        "NN_COLOR           = 'single'                   # Input Color Space           ('single'/'multi')\n",
        "NN_FINETUNE        = 'full'                     # Trainable Layers            ('full'/'classifier'/Starting Layer Name)\n",
        "NN_WEIGHTS         = None                       # Pre-Trained Encoder Weights ('imagenet'/None)\n",
        "TRAIN_SCHEME       = 'clean'                    # Training Scheme             ('clean'/'warm'/'freeze'/'resume')\n",
        "DROPOUT            = False                      # Dropout Regularization\n",
        "EPOCHS             = 7\n",
        "AUX_EPOCHS         = 1\n",
        "TTA                = True                       # Test-Time Augmentation\n",
        "TTA_MODE           = 'mean'                     # TTA Aggregation             ('mean'/'maxconf')\n",
        "\n",
        "# Learning Rate Hyperparameters\n",
        "BASE_LR            = 1e-5\n",
        "MODE_LR            = 'CLR'\n",
        "\n",
        "# I/O Parameters\n",
        "CLASS_NAMES        = ['nv','les']\n",
        "TRAIN_SAMPLES      = 4800\n",
        "VAL_SAMPLES        = 1200\n",
        "IO_X               = 450                        # Original Dimensions\n",
        "IO_Y               = 600                        # Original Dimensions\n",
        "CROP_FACTOR        = 1.00                       # Crop Percentage\n",
        "DIM_X              = 448                        # Cropped Training Dimensions\n",
        "DIM_Y              = 448                        # Cropped Training Dimensions\n",
        "BATCH_SIZE         = 4                          # Mini-Batch Size"
      ],
      "metadata": {
        "id": "6s2rijfo3gBI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_DIR    = '/content/gdrive/MyDrive/imagenet-mini/val'    \n",
        "TEST_MODE   = 'val'                      # 'val'/'test'\n",
        "\n",
        "\n",
        "def findScan(data, name, key):\n",
        "  for i, dic in data.items():\n",
        "    if dic[key] == name:        \n",
        "      return i\n",
        "    return -1\n",
        "\n",
        "def test_io(path,mode):\n",
        "  \"\"\"\"\n",
        "  Input:  path\n",
        "  Output: data[p] = {\n",
        "      'id':\n",
        "      'image':\n",
        "      'label': }\n",
        "  \"\"\"\n",
        "  if (mode=='test'):\n",
        "    # Importing Images\n",
        "    target_dir  = glob.glob(path+\"/les/*.png\")\n",
        "    print(\"Number of Test Images:\", len(target_dir))\n",
        "    \n",
        "    # Creating Dictionary\n",
        "    data = {}\n",
        "    for p in range(len(target_dir)):\n",
        "        scan_id  =  target_dir[p].replace(\".jpeg\", \"\")\n",
        "        scan_id  =  scan_id.replace(path+\"\\\\\", \"\")\n",
        "        # Creating List of Dictionary                    \n",
        "        data[p] = {'id'    : scan_id,\n",
        "                   'image' : target_dir[p] }\n",
        "  \n",
        "  elif (mode=='val'):\n",
        "    # Importing Images\n",
        "    les_dir = glob.glob(path+\"/les/*.jpeg\")\n",
        "    nv_dir  = glob.glob(path+\"/nv/*.jpeg\")\n",
        "    print(\"Number of LES Images:\", len(les_dir))\n",
        "    print(\"Number of NV Images:\",  len(nv_dir))\n",
        "    \n",
        "    # Creating Dictionary (LES Scans)\n",
        "    data = {}\n",
        "    for p in range(len(les_dir)):\n",
        "      scan_id  =  les_dir[p].replace(\".jpeg\", \"\")\n",
        "      scan_id  =  scan_id.replace(path+\"/les\\\\\", \"\")\n",
        "      # Creating List of Dictionary                    \n",
        "      data[p] = { 'id'    : scan_id,\n",
        "                  'image' : les_dir[p],\n",
        "                  'label' : 1 }                         # Label of LES = 1\n",
        "\n",
        "    # Creating Dictionary (NV Scans)\n",
        "    for p in range(len(nv_dir)):\n",
        "      scan_id  =  nv_dir[p].replace(\".jpeg\", \"\")\n",
        "      scan_id  =  scan_id.replace(path+\"/nv\\\\\", \"\")\n",
        "      # Creating List of Dictionary                    \n",
        "      data[p+len(les_dir)] = { 'id'    : scan_id,\n",
        "                               'image' : nv_dir[p],\n",
        "                               'label' : 0 }            # Label of NV = 0\n",
        "  return data"
      ],
      "metadata": {
        "id": "sk-TsV2D3i3g"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_DIR    = '/content/gdrive/MyDrive/imagenet-mini/val'    \n",
        "TEST_MODE   = 'val'                      # 'val'/'test'\n",
        "\n",
        "from tfkeras.preprocessing.image import Image DataGenerator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "SsM26_X07oMc",
        "outputId": "f951dd21-c612-4be8-fee4-d46001e9e59c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-4f2c638bc6a3>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    from tfkeras.preprocessing.image import Image DataGenerator\u001b[0m\n\u001b[0m                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Testing Dataset for Full Inference\n",
        "test_dataset   = test_io(path=TEST_DIR, mode=TEST_MODE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmpQnQzi3mRY",
        "outputId": "78c7ffc4-2a8e-4349-d949-2727be56f5b6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of LES Images: 0\n",
            "Number of NV Images: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (NN_COLOR=='single'):\n",
        "  DIM_CHANNELS = 3\n",
        "  TRAIN_DIR    = '../data/grayworld/train/'\n",
        "  VAL_DIR      = '../data/grayworld/val/'\n",
        "  \n",
        "elif (NN_COLOR=='multi'):\n",
        "  DIM_CHANNELS = 9\n",
        "  TRAIN_DIR    = '../data/raw/train/'\n",
        "  VAL_DIR      = '../data/raw/val/'\n",
        "  DATASET_MEAN = [0.610446659205108800, 0.5220753348750297000, 0.5095079890928187000,\n",
        "                  0.545083657305597700, 0.3857680235700908000, 0.7072208299516552000,\n",
        "                  1.435617385489288400, 1.1975180678760260000, 1.0724577830134300000] # [R,G,B,H,S,V,L,a,b]\n",
        "  DATASET_STD  = [0.011219814446842410, 0.0114450729879776450, 0.0104303418370314950,\n",
        "                  0.008512948157193818, 0.0082573833265490880, 0.0162066173083936020,\n",
        "                  0.028451386706097037, 0.0018845362785246164, 0.0038278101960121606] # [R,G,B,H,S,V,L,a,b]\n",
        "\n",
        "def process_path(file_path):\n",
        "  # Derive Label\n",
        "  parts = tf.strings.split(file_path, os.path.sep)        # Split Path into Components\n",
        "  parts = parts[-2] == CLASS_NAMES                        # Generate One-Hot Encoded Label\n",
        "  label = tf.argmax(tf.dtypes.cast(parts,tf.float32))     # Convert to Single Digit Label                        \n",
        "  \n",
        "  # Derive Image\n",
        "  if (NN_COLOR=='single'):\n",
        "    img   = tf.io.read_file(file_path)                                                # Load RAW Data from File as String\n",
        "    img   = tf.image.decode_jpeg(img, channels=DIM_CHANNELS)                          # Convert RAW Data to a 3D uint8 Tensor\n",
        "    img   = tf.image.convert_image_dtype(img, tf.float32)                             # Convert to Floats in Range [0,1]\n",
        "    img   = tf.image.crop_to_bounding_box(img,(IO_X-DIM_X)//2,                        # Crop Image to Central Target\n",
        "                                              (IO_Y-DIM_Y)//2,\n",
        "                                               DIM_X,DIM_Y)                                            \n",
        "  elif (NN_COLOR=='multi'):\n",
        "    img   = tf.io.read_file(file_path)                                                # Load RAW Data from File as String\n",
        "    img   = tf.reshape(tf.io.decode_raw(img,tf.float32), [IO_X,IO_Y,DIM_CHANNELS])    # Convert RAW Data to a 3D float32 Reshaped Tensor\n",
        "    img   = tf.image.convert_image_dtype(img, tf.float32)                             # Convert to Floats in Range [0,1]\n",
        "    img   = tf.image.crop_to_bounding_box(img,(IO_X-DIM_X)//2,                        # Crop Image to Central Target\n",
        "                                              (IO_Y-DIM_Y)//2,\n",
        "                                               DIM_X,DIM_Y) \n",
        "  return img, label\n",
        "\n",
        "def train_io(file_path):\n",
        "  img, label = process_path(file_path)                                                # Process Filepath to Obtain Image, Label Pair \n",
        "  # Train-Time Spatial Augmentation\n",
        "  img  = tf.image.random_flip_left_right(img)                                         # Horizontantal Flip (50% Probability)\n",
        "  img  = tf.image.random_flip_up_down(img)                                            # Vertical Flip (50% Probability)\n",
        "  if (NN_COLOR=='single'):\n",
        "    # Train-Time Intensity Augmentation\n",
        "    img  = tf.image.random_brightness(img, max_delta=0.25)                            # Random Brightness Augmentation\n",
        "    img  = tf.image.random_saturation(img, lower=1.00,upper=1.25)                     # Random Saturation Augmentation\n",
        "    img  = tf.image.random_contrast(img, lower=1.00,upper=1.25)                       # Random Contrast Augmentation\n",
        "    img  = tf.clip_by_value(img, 0.0,1.0)                                             # Ensure intensity range in [0, 1]\n",
        "  if (NN_COLOR=='multi'):\n",
        "    # Normalization (Mean=0, Std=1)\n",
        "    mean_tensor = tf.constant(np.ones(shape=(DIM_X,DIM_Y,1))*DATASET_MEAN, tf.float32)\n",
        "    std_tensor  = tf.constant(np.ones(shape=(DIM_X,DIM_Y,1))*DATASET_STD,  tf.float32)\n",
        "    img         = (img-mean_tensor)/std_tensor\n",
        "  return img, label\n",
        "\n",
        "def val_io(file_path):\n",
        "  img, label = process_path(file_path)                                                # Process Filepath to Obtain Image, Label Pair \n",
        "  if (NN_COLOR=='multi'):\n",
        "    # Normalization (Mean=0, Std=1)\n",
        "    mean_tensor = tf.constant(np.ones(shape=(DIM_X,DIM_Y,1))*DATASET_MEAN, tf.float32)\n",
        "    std_tensor  = tf.constant(np.ones(shape=(DIM_X,DIM_Y,1))*DATASET_STD,  tf.float32)\n",
        "    img         = (img-mean_tensor)/std_tensor\n",
        "  return img, label"
      ],
      "metadata": {
        "id": "nGYUA_333qxw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Dataset of Filepaths\n",
        "train_list = tf.data.Dataset.list_files(str(TRAIN_DIR+'*/*'))\n",
        "val_list   = tf.data.Dataset.list_files(str(VAL_DIR+'*/*'))\n",
        "\n",
        "# Multiple Images Loaded/Processed in Parallel from Labeled One-Hot Encoded Dataset\n",
        "labeled_train_data = train_list.map(train_io, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "labeled_val_data   = val_list.map(val_io, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "for image, label in labeled_train_data.take(1):\n",
        "  # Verify Example (Redundancy Check)\n",
        "  print('Data Type/Shape')\n",
        "  print('image: ', (image.numpy()).dtype, (image.numpy()).shape)\n",
        "  print('label: ', (label.numpy()).dtype, (label.numpy()).shape)\n",
        "  print('--------------\\nExample Pair\\nLabel: ', (label.numpy()))\n",
        "  plt.imshow(image.numpy()[:,:,1],cmap='gray')\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "Hp6lLIaZ3sdg",
        "outputId": "a3ec1835-0c4d-4e9d-8c67-9d8da44f24e7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-d2730a114317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate Dataset of Filepaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'*/*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_list\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAL_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'*/*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Multiple Images Loaded/Processed in Parallel from Labeled One-Hot Encoded Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mlist_files\u001b[0;34m(file_pattern, shuffle, seed, name)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m       assert_not_empty = control_flow_ops.Assert(\n\u001b[0;32m-> 1380\u001b[0;31m           condition, [message], summarize=1, name=\"assert_not_empty\")\n\u001b[0m\u001b[1;32m   1381\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massert_not_empty\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m         \u001b[0mmatching_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mAssert\u001b[0;34m(condition, data, summarize, name)\u001b[0m\n\u001b[1;32m    157\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m           \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Expected '%s' to be true. Summarized data: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m           (condition, \"\\n\".join(data_str)))\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: ../data/grayworld/train/*/*'"
          ]
        }
      ]
    }
  ]
}